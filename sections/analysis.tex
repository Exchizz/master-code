\chapter{Analysis}
\section{Design requirements}
The proposed system is designed with the concepts of the unix philosophy in mind
\begin{itemize}
	\item Programs should do one thing, and do it well
	\item Programs should be able to work together
	\item Programs should be capable of taking streams of text as input
\end{itemize}

By complying with the three ideas from above, the system should consist of multiple small programs that can be put together in different ways to serve different purposes.

Since the system is developed for biologists, it should be easy to use and require minimum intervention to get it running. Ideally the system should be “plug and play” such that biologists can take the number of recording boxes required for their application and put it all together without the need to configure software on any of the boxes. \todo{Add Extensibility somewhere, maybe not due to maintainability}



\todo{Add: Write as little code as possible, use already existing code maintained by other developers}
\todo{add: Should be a requirement that it should be easy to write new nodes. Should not require an interface to send commands, should be self-contained as possible.}

Furthermore the system should also be:

\begin{itemize}
	\item Maintainability
As other people will improve the system in the future, it should also be easy to maintain. This will almost happen automatically if the “unix design rules” are kept in mind during design and development.
\item Modular
The system should consist of multiple small programs so that it can be used in all existing use-cases but also those that might come in the future.
\item Reusability
As much code should be as reusable as possible in order to avoid implementing the same functionality multiple times.
\item Extensible
    By implementing small programs, the system should be easy to extend in the future.
    If functionality is missing in one of the programs, it should be possible to create a new 
    program with the new functionality.
\end{itemize}

However splitting functionality into multiple modules will also be done with caution as it might come with the price of performance. Each time programs are split up, there is usually required some communication between the programs or some exchange of memory. The communication might turn out to be unnecessary performance consumption. Therefore splitting programs up is seen as simplicity(as it eases development and use) vs. performance.

% \section{Recording}
% stream data out
% timestamp for accurately compare streams\todo{verify with John}


\begin{figure}[h!]
	\includegraphics[width=1\textwidth]{figures/analysis-terminilogy-overview.png}
	\caption{Overview of nodes, to ease understanding of the terminology used throughout the following sections. It should be noted, that the producer and consumer is just programs producing and consuming streams without being aware of the protocols between the producer and subscriber.}
\end{figure}

\section{Streams}
% A streams is an abstraction, that hides the details in the communication between subscribers and publishers.
A stream is defined as coherent data, which is in the process of being transmitted. A stream does not conceptually have an explicit beginning or end nor does it necessarily have a header explaining the content of the stream. A stream can either be continuous or discrete which depends on the content of the stream. 


Given use case \ref{usecase:x}, the stream must be capable of comprising sound, text and video formats only relying on codecs available. As all streams are transmitted over multicast groups, the streams must be packet-oriented since they are transported as UDP packets.
As UDP packets might arrive out of order, or not arrive at all, the stream must be robust to lost packets, without loosing global knowledge of the stream.
TCP is not considered an option, as this would not take advantage of the multicast groups. TCP is connection-oriented meaning it would require a connection from each producer to each consumer, this would limit the number of consumers per producer due to the RPI's bandwidth limitation.

Both publisher and subscriber is stateless with respect to the data streams. However, they might both maintain a state about the metadata streams.

Since the stream is just data, there must be metadata available that describes the content of the streams. The streams must be described unambiguously, such that each stream can be differentiated from the other streams. Since the streams are to be recorded and replayed, metadata must also be available when the streams are replayed, in order to identify the streams when replayed. Therefore, the streams must be complete and depend on no external knowledge.
As the system will usually comprise of multiple streams, each stream must have a unique, sensible name used to refer to the stream. Furthermore it must have an unique identifier that allow streams to refer to eachother.
As in use case \ref{usecase:energizer}, where a node consumes a stream and produces a new stream, the new stream must explicitly specify its parent stream using the parent's unique identifier. This gives rise to model the streams as a forest of graphs, where each graph should always be an directed acyclic graph, in order to avoid streams that depend on themselves.

\todo{Figure of example graph}

\section{Producers and Consumers}
As streams may contain different formats, the producer and consumer must be agnostic to the content of the stream, and must handle the data to and from the stream.
Multiple consumers and producers must be able to subscribe and publish to the same multicast group, however the producer and consumer must give a warning, if the topic is already used by another producer. In order for this to work, the consumers and producers must implement a presence protocol, that detects the presents of other producers and consumers on a specific stream. This must be implemented in a way such that possible conflicts can be detected within X seconds from a producer/consumer is run, where X is specified as a parameter to the nodes.

As there is no designated master in the system, the producers must be designed such that that independently can find available multicast groups, without relying on too many well-known multicast groups. When a consumer is used to subscribe to a stream using the stream's unique name, the consumer must single-handedly be able to find the requested multicast group.
As producers and consumers unlikely joins multicast groups at the same time, the producer and consumers most be able to cope with nodes asynchronously joining and leaving multicast groups.

Both producer and consumer must be implemented as C-libraries and support bindings to other languages, to ease implementing new consumers and producers for future applications.

From use case \ref{sec:usecase:energizer}, the energy calculation should happen from bulk of samples corresponding to 1 ms. To ease the implementation of the energizer-node and future nodes, it should be possible to set the payload size of the publisher node. If the payload length of the stream corresponds to 1 ms of samples, the energizer node do not have to implement a buffer mechanism. If the length of the packet exceeds the practical limits of the network, the producer must give a warning. From the incoming data to the producer, and the outgoing data from the consumer, there should be no limit of the packet sizes.

As metadata is required, it must be possible to provide metadata to the publishers such that it can stream it to the subscribers. 

\section{Metadata}
% Analysis of metadata
	% Metadata 
	% Sequence number in packet.
Metadata is required to describe how streams are encoded,
, producers and consumers uniquely. The metadata must be recorded such that when the streams are replayed the same metadata must be available.

The metdata can be split into three categories:
\begin{itemize}
	\item \textbf{PTR}-metadata is the metdata that concerns with pointing to a high bandwidth stream from the metadata stream.
	\item \textbf{Internal stream}-metadata describes the stream such as codec, sample frequency etc.
	\item \textbf{External stream}-metadata describes properties of the stream that relates to the source-node. In case of a batbox this will be box-uuid, microphone parameters etc.
\end{itemize}


\textit{PTR} metadata is required in order for the subscriber nodes to know the multicast address of high bandwidth data stream. 

\textit{Internal stream}-metadata is required to describe the content of the stream.
The coding of the stream must be retransmitted periodically with rate N such that new subscribers joining a particular high-bandwidth stream will have to wait a maximum of $\frac{1}{N}$ secs to receive a description of the stream.
\textit{External stream}-metadata

The metadata can be considered a discrete stream that is periodically transmitted as one-shot packets.
As with the datastream, metadata will be sent as UDP packets, but to a well-known topic that all subscribers and publishers know when run.
When metadata is published, it should have a checksum attached that allows detecting if the content of the metadata has changed during transfer.

\begin{enumerate}
	\item \textit{Internal stream}-metadata must be retransmitted periodically.
\end{enumerate}

% Layers of metadata:
% - datastream contains metadata(seq id, 32 bit timestamp)
% - metdata on metadatastream(streamid, streamname, multicast stream)
% - Metadata regarding e.g batbox

\subsection{Requirements}
From the analysis, the following requirements can be extracted.
\subsubsection{Streams}
\begin{enumerate}
	\item The stream can be either continuous or discrete.
	\item The stream must comprise different datatypes only by relying on available codecs.
	\item The stream must be packet-oriented and stateless
	\item The stream must be transported over UDP
	\item The stream must be robust to UDP packets that arrive out of order or never arrive.
	\item The stream must be represented unambiguously
	\item Metadata must be provided by the publishers and be available to the subscribers 
\end{enumerate}

\subsubsection{Producer \& Consumer}
\begin{enumerate}
	\item The producer and consumer must be agnostic to the stream's payload.
	\item Multiple producers must send to the same multicast group.
	\item Multiple consumers must receive from the same multicast group.
	\item The producers and consumers must implement a presence mechanism to know about other producers and consumers.
	\begin{enumerate}
		\item It must takes a finite maximum number of seconds for a producer or subscriber to know who is present. The max time must be a parameter of each node.
		\item It must take a finite maximum number of seconds for a producer or consumer to detect whether a multicast group is in use, and if yes, by whom.
		\item It must assume nodes leaving a multicast group sends a "bye".
		\item It must be robust to "bye"-messages not arriving to all nodes.
		\item It must handle nodes joining and leaving at any arbitrary time.
	\end{enumerate}
	\item The producers must be able to find unused multicast groups single-handedly.
	\item Given a unique name of a stream, the consumer must be able to resolve the multicast address of the stream.
	\item Both producers and consumers must be able to cope with nodes joining asynchronously.
	\item The producer and consumer must be implemented in C and support language bindings.
	\item The payload length of the stream should be adjustable as a parameter on the producer nodes.
		\begin{enumerate}
			\item If the requested payload size is exceeded practical limits, a warning must be given.
		\end{enumerate}
	\item There should not be a limit of the packet size of the incoming data to the producer, or outgoing data from the consumer.
	\item The producer must support streaming provided metadata to the consumers.
	\item Both producer and consumer must be agnostic with respect to the semantics of the metadata.
\end{enumerate}

\subsubsection{Metadata}
As stated in the Streaming-section, metadata must be provided in order to know what the content of the stream is.

As UDP is chosen, each packet must contain a sequence number that allows detecting packets received out of order, or lost packets.

\begin{enumerate}
	\item The stream must contain a sequence number.
\end{enumerate}

\section{Historian}
Storing data is essential in use cases, that requires post-processing of recordings. As opposed to the existing system, saving recordings to a local disk should be the only responsible of a designated node referred to as historian.
The historian should not be limited to record one box, but should be capable of saving recordings from multiple recording boxes.

From use case x-y, the historian should be able to save the following three types of recordings:
\begin{itemize}
	\item Long recordings
		In order for the node to save long recordings, it should be capable of writing 			to a local disk periodically, and not store the entire recording in memory, 			as this would limit the maximum recording time. As the node should be responsible for 				saving multiple streams, it should save the streams with its metadata, such that the streams can be identified when processed.
	\item Short recordings
		With short recordings, the same applies as longtime recordings, however it 				should be possible to decide when and for how long time the recording node should 			run.
	\item Trigger recordings
		From use case \ref{usecase:trig}, trigger recording is required. The Historian must be able to replay a recording of arbitrary length at a arbitrary time of recorded data.
\end{itemize}


\subsection{Replaying}
Due to the nature of the streaming-idea, the historian should export its stored recordings by replaying its streams from a given time and data. For this to work, the historian must have an interface that allows requesting the following:

\begin{itemize}
	\item Date and time from where the historian will replay the streams.
	\item It should support selecting which streams to be replayed.
	\item To which interface the streams should be replayed. This will be useful in the use case \ref{usecase:trigger}, where requesting data might happen meanwhile the historian is recording.
	\item Replay rate that allows selecting how fast the replaying should happen. In use cases where the historian needs to dump a stream for post processing, the replaying should happen as fast as possible.
\end{itemize}

\subsection{Autodiscover of new streams}
As there is no guarantee that all batboxes are powered up when the historian starts recording, the historian must be able to autodiscover batboxes, in order to known which multicast groups to join. The batboxes must periodically resend this message, so that the historian knows which topics to join when the batboxes are powered up before the historian.
 In order for this to work, a topic should be reserved for batboxes to announce their existence, from where the historian can listen. 

A batbox should provide the following information:
\begin{itemize}
	\item Its name, e.g. Batbox1
	\item A descriptive name, e.g. "Batbox in tree"
	\item List of topics it publishes to
	\item Its IP
\end{itemize}
 

This will also be useful in use case \ref{usecase:verifyWorking}, as this provides a way for the system to collect information about which batboxes are successfully connected to the system.
Furthermore, 


\section{Geometric Calibration}
% Node to consume the stream and provide metadata.


\section{Energy Calculator}
% Node responsible for calculating energy in signal. 

\section{Scalability}
From use case \ref{usecase:multibox}, it is required that the system is capable of handling multiple recording boxes. The system is designed to be scalable meaning there should be no device on the network, that limits the number of nodes in the system. As each batbox announce their existence to a multicast group, and that the historian saves streams, the system supports having multiple historians connected to the system. 

\section{Network}
As all streams leaving the nodes are timestamped, there is no restrictions on how the devices should be connected on the network. Packets can go through different number of hobs without causing problems, if the timestamps from the streams are used, and not the order the packets are leaving the historian during replay.

To connect multiple hosts on the network, multiple switches can be connected together. If multiple switches are connected, the bandwidth between switched should be handled with care. Each batbox generates 40 Mbit/s of data, so if a 24 ports switch is used to connect 23 batboxes and one historian, the link between the switch and the historian must be 1 Gbit. If an 48 ports switch is used, 1.8 Gbits is required between the switch and the historian. It should be noted, that a switch's non-blocking capacity, meaning the bandwidth it can handle at the same time, rarely equals the (number of ports) x (the bandwidth of each port).

Each switch must support the following features in order to handle IPv6 multicast traffic properly.

\begin{itemize}
	 \item IGMP snooping, in order to avoid broadcasting multicast traffic.
	 \item MLD, protocol used by IPv6 to join and leave multicast groups.
\end{itemize}

If the system scales out enough, limitations might arise, however these are not seen as realistic limitations.

\section{System Management}
\subsubsection{IP}
\todo{design requirement, scalable}
\todo{Define host}
As one of the design requirements is the system is scalable, it is not convenient to have a DHCP server on the network. IP's can be statically assigned, however this is cumbersome of many hosts are in use. It has been chosen to use IPv6 stateless configuration due to the following arguments:
\begin{itemize}
	\item No DHCP server is required
	\item No single poing of failre, as each device figures out if the IP is in use
	\item 
\end{itemize}

What could become a problem is, how to know the IP of each batbox, if each box figures an IP for itself. This is automatically solved by using autodiscover discussed in section \ref{sec:analysis:autodiscover}.

\subsection{Configuration}
% Existing system uses ZMQ, use ansible for deployment of configurations.
Parameters in the existing system
The existing snapshot supports four ways to set parameters, with the following priority.
\begin{itemize}
	\item Build-in defaults
	\item Environment variables
	\item Command line variables
	\item ZMQ parameters
\end{itemize}

Not all parameters can be set at runtime using ZMQ, which is further specified in the manpage to snapshotter.


\subsection{Deployment of software}

\section{Requirements}
The following section summarizes the requirements extracted from the analysis and use cases.

\todo{Table of requirements[Where it's defined][Where it's tested][Whether it passes<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<]}

The following two approach has been found:
\begin{itemize}
	\item Self-identifying streams. The streams contains the metadata itself. That means the producer must read the stream in order to figure out, what the content of the stream is.
	\item Metadata topic. A topic could be reserved for metadata. All producing nodes would then publish to the meta-topic which streams they publish and where the actual datastream can be found.
\end{itemize}
Both of the ideas above have pros and cons, which is described in table \ref{table:streamsproscons}.


