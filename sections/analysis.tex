\chapter{Analysis}
In order to develop and implement programs to send and receive streams, the requirements from the use cases must be extracted.
%Some requirements will be logical consequences or decisions in order to nail down details.
This section will constitute an analysis to such a degree where the design section can discuss which protocol(s) to use.

\section{Assumptions}
During the analysis, design and implementation sections the following assumptions have been made:
\begin{itemize}
	\item No packets are lost or corrupted during transmission.
	\item No bandwidth limitation exists on the network.
\end{itemize}

\todo{Add reason to assumptions, more through description}
\todo{Discuss assumptions in \textit{Discussion}-section}
\section{Design Requirements}
The proposed system is designed with the concepts of the unix philosophy in mind
\begin{itemize}
	\item Programs should do one thing, and do it well
	\item Programs should be able to work together
	\item Programs should be capable of taking streams of text as input
\end{itemize}

\todo{"always use the simplest solution possible" (Rich, 1995, pp. 221 and 231) and McIlroy
recommends (slightly modified) "creating components that do one thing and do it well"}

By complying with the three ideas from above, the system should consist of multiple small programs that can be put together in different ways to serve different purposes.

Since the system is developed for biologists, it should be easy to use and require minimum intervention to get it running. Ideally the system should be “plug and play” such that biologists can take the number of recording boxes required for their application and put it all together without the need to configure software on any of the boxes. \todo{Add Extensibility somewhere, maybe not due to maintainability}

\todo{Stram op...}

\todo{Add: Write as little code as possible, use already existing code maintained by other developers}
\todo{add: Should be a requirement that it should be easy to write new nodes. Should not require an interface to send commands, should be self-contained as possible.}

\todo{Design inspired by Daniel J. Bernstein, software run in "chains"}
Furthermore the system should also be:

\begin{itemize}
	\item Maintainability
As other people will improve the system in the future, it should also be easy to maintain. This will almost happen automatically if the “unix design rules” are kept in mind during design and development.
\item Modular
The system should consist of multiple small programs so that it can be used in all existing use-cases but also those that might come in the future.
\item Reusability
As much code should be as reusable as possible in order to avoid implementing the same functionality multiple times.
\item Extensible
    By implementing small programs, the system should be easy to extend in the future.
    If functionality is missing in one of the programs, it should be possible to create a new 
    program with the new functionality.
\end{itemize}

However splitting functionality into multiple modules will also be done with caution as it might come with the price of performance. Each time programs are split up, there is usually required some communication between the programs or some exchange of memory. The communication might turn out to be unnecessary performance consumption. Therefore splitting programs up is seen as simplicity(as it eases development and use) vs. performance.

% \section{Recording}
% stream data out
% timestamp for accurately compare streams\todo{verify with John}


\begin{figure}[h!]
	\includegraphics[width=1\textwidth]{figures/analysis-terminilogy-overview.png}
	\caption{Overview of nodes, to help the reader understand the terminology used throughout the following sections. It should be noted, that the producer and consumer is just programs producing and consuming streams without being aware of the protocols between the publisher and subscriber.}
\end{figure}

\section{Streams}
% A streams is an abstraction, that hides the details in the communication between subscribers and publishers.
A stream is defined as coherent data, which is in the process of being transmitted. A stream does not conceptually have an explicit beginning or end nor does it necessarily have a header explaining the content of the stream. A stream can either be continuous or discrete which depends on the content of the stream. 


Given use case \ref{usecase:x}, the stream must be capable of comprising sound, text and video formats only relying on codecs available. As all streams are transmitted over multicast groups, the streams must be packet-oriented since they are transported as UDP packets.
As UDP packets might arrive out of order, or not arrive at all, the stream must be robust to lost packets, without loosing global knowledge of the stream.
TCP is not considered an option, as this would not take advantage of the multicast groups. TCP is connection-oriented meaning it would require a connection from each producer to each consumer, this would limit the number of consumers per producer due to the RPI's bandwidth limitation.

All nodes that publish and subscrib is stateless with respect to the data streams. However, they might both maintain a state about the metadata streams.

Since the stream is just data, there must be metadata available that describes the content of the streams. The streams must be described unambiguously, such that each stream can be differentiated from the other streams. Since the streams are to be recorded and replayed, metadata must also be available when the streams are replayed, in order to identify the streams when replayed. Therefore, the streams must be complete and depend on no external knowledge.
As the system will usually comprise of multiple streams, each stream must have a unique, sensible name used to refer to the stream. Furthermore it must have an unique identifier that allow streams to refer to eachother.
As in use case \ref{usecase:energizer}, where a node consumes a stream and produces a new stream, the new stream must explicitly specify its parent stream using the parent's unique identifier. This gives rise to model the streams as a forest of graphs, where each graph should always be an directed acyclic graph, in order to avoid streams that depend on themselves.

\begin{figure}[h!]
	\includegraphics[width=1\textwidth]{figures/stream-graph}
\end{figure}

\section{Metadata}
\subsection{Introduction}\todo{Self-identifying streams in analysis}

By inspection of the use cases and the streaming analysis in section \ref{sec:analysis}, it has been decided to split metadata into tree categories:
\begin{enumerate}
	\item \textit{Essential metadata} which covers the metadata that is required to identify and decode the stream.
	\item \textit{Non-essential metadata} which is used between the producer and consumer. This metadata is only relevant to the users.
	\item \textit{Events} which describes an event in the stream. An event is defined as something interesting in the stream.
\end{enumerate}

\subsection{Event}
From use case \ref{usecase:batbox}, it is required that the system can handle events consisting of the following entries:
\begin{itemize}
	\item \textit{Start} States the absolute date and time of when the event appear. 
	\item \textit{Duration} States for how long time the event is active.
	\item \textit{Data} Associates data to the event. This can either be entered by a user or by a node on the network.
\end{itemize}

Given that streams are to be recorded replayable, the events must also be replayable while still relating to a stream and point in time explicit and unambiguously.

\subsection{Essential Metadata}
From the analysis of streams ~\ref{analysis:stream}, it is required that the streams are self-identifying to the subscriber. This implies that metadata that describes the properties of the stream must be available to the subscriber.
From analysis of streams ~\ref{analysis:stream:requirement:x}, it is required that subscribers can join a stream at any arbitrary time. In order for the subscriber to know the properties of the stream, the metadata must be retransmitted periodically. This metadata is essential in order to identify and decode the stream and will be referred to as "essential metadata".\\

\subsection{None-essential Metadata}
The existing batboxes provide metadata about the streams, which is not essential to identify or decode the stream but is relevant to the user or consumer. An example of this is listed below.
\begin{itemize}
	\item Batbox-uuid
	\item Batbox's filter settings
	\item Microphone parameters
\end{itemize} 
The publishers and subscribers must be agnostic to the semantics of this metadata, as it is provided by the producer and used by the consumer. The subscriber and publisher must allow for conversion between different formats used by the producer and consumer, in order to ease implementing producers and consumers.
%The subscriber and publisher must also be agnostic to the format of the metadata, as the producer and consumer might use XML, JSON, EMBL etc. to represent metadata.
This will be referred to as "none-essential metadata", as this metadata is not essential with respect to the streams.\\

\subsection{Metadata Format}
From the design requirements, the metadata must be extensible such that the structure and list of parameters can be adopted as needed.

Given the analysis and design requirements, it has been decided, that metadata is essentially hierarchical key-value structures, that can be represented in different formats. From that decision the following requirements are fulfilled:
\begin{itemize}
	\item Extensible - as new key-value pairs can be added as needed.
	\item Expressive - since associative arrays, arrays etc. can be expressed.
	\item Convertable - as both subscribers and publishers can convert into the format required by the consumer and publishers independently.
\end{itemize}

\section{Publishers \& Subscribers}
\subsection{Introduction}
The terminology used to describe streams throughout the analysis is used from RFC7656.

Nodes publishing streams will be referred to as publishers through the following sections. Nodes receiving streams will be referred to as a subscriber, as they subscribe to streams in order to get the streams. \\
A subscriber and publisher is depicted in figure \ref{fig:analysis:pubsub}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{figures/publisher-subscriber}
    \end{subfigure}
     \caption{A publisher(left) and subscriber(right) depicted}\label{fig:analysis:pubsub}
\end{figure}

A source stream is defined as a stream of digital samples that has been synchronized with a reference clock and comes from a particular media source.

A packetized source stream is defined as a source stream where the stream is split into packets.
The outgoing source stream is identical to the oncoming source stream.
Non-essential metadata is as defined in \ref{sec:analysis:metadata}. Incoming none-essential metadata will be the same as the outgoing none-essential metadata.

The \textit{outgoing metadata stream} is \textit{none-essential} and \textit{essential metadata} combined as \textit{essential metdata} is used by the publisher and subscriber.

\subsection{Analysis}
As streams may contain different media, the publisher and subscriber must be agnostic to the codec of the stream, and must provide an interface to handle the data as well as metadata to and from the streams.
In order to allow multiple nodes to use a stream, multiple subscribers must be able to subscribe to the same multicast group. If a publisher publishes to a topic already in use, it must give a warning to the user. In order for this to work, the publishers and subscribers must implement a presence protocol, that detects the presents of other publishers and subscribers on a specific stream. This must be implemented in a way such that possible conflicts can be detected within X seconds from a publisher/subscriber is run, where X is specified as a parameter to the nodes.

As there is no designated master in the system, the publisher must be designed such that that independently can find available multicast groups, without relying on too many well-known multicast groups. When a subscriber is told to subscribe to a stream using the stream's unique name, the subscriber must single-handedly be able to find the requested multicast group.
As publishers and subscribers unlikely joins multicast groups at the same time, the publisher and subscriber most be able to cope with nodes asynchronously joining and leaving multicast groups.

Given design requirement X in section \ref{sec:analysis:designrequirements}, the publishers/subscribers must be opaque such that they encapsulate all of their internal protocols. In practice this means that the producers and consumers must be unaware of the communication between the subscribers and publishers.

%Both producer and consumer must be implemented as C-libraries and support bindings to other languages, to ease implementing new consumers and producers for future applications.

%The publishers and subscribers must react to

As metadata is required, it must be possible to provide metadata to the publishers such that it can stream it to the subscribers.
Given that the subscribers and publishers work on incoming data from either a stream or producer, they should only do work if 1) data from a stream is received or 2) the node must do work periodically.


\section{Historian}

Storing data is essential in all use cases, that require post-processing of recordings. Saving recordings to a local disk and later replay the recordings should be the only responsibilities of a designated node referred to as historian.
The historian should not be limited to record one stream, but should be capable of saving recordings from multiple streams. 

From use case \ref{sec:uc:x}, the historian should be able to save the following three types of recordings:
\begin{itemize}
	\item Long recordings
		In order for the node to save long recordings, it should be capable of writing to a local mounted storage periodically, and not store the entire recording in memory, as this would limit the maximum recording time.

	\item Short recordings
		With short recordings, the same applies as longtime recordings, however it should be possible to decide when and for how long time the recording should run. The historian must provide an interface that allows setting when to do recordings and for how long time.
	\item Trigger recordings
		From use case \ref{usecase:trig}, trigger recording is required. The historian must be able to replay a recording of arbitrary length at a arbitrary time of recorded data. This implies that the recording must support recording while replaying recordings. For this to work, it must be possible to specify which interface the historian should replay the recordings to.
\end{itemize}

As the node should be responsible for recording multiple streams, it should save the streams unambiguously with their associated metadata, such that the streams can be uniquely identified when replayed.
Given that streams can contain different media and encodings, the historian must be agnostic to the content of the stream.

Given that it might be possible that a stream must not be recorded, the historian must support ignoring streams that explicit states not to be recorded.



% Record multiple high and low bandwidth data streams


\subsection{Replaying}
Since the nodes processing the streams should be run when the streams are recorded, online or after the streams has been recorded, offline, the historian must replay the streams such that a processing nodes is unaware of the streams are live or replayed. This implies that the stream must be replayed in same order as it is recorded and in real-time meaning x seconds of recording takes x seconds to replay. Furthermore, this implies that metadata recorded must be replayed with the streams, also in real-time.
 From usecase \ref{sec:usecase:post-processing} it is required to be able to replay the same recordings multiple times. This implies that the historian must not delete the recordings after the recording has been played the first time.
As the historian saves streams and metadata with respect to time, the replaying must be started by requesting a replay from a given time and date. It should also be possible to send for how long the historian should replay, so that a replay will not default continue until stopped. For this to work, the historian must have an interface that allows requesting the following:


\begin{itemize}
	\item Date and time from where the historian should replay the streams.
	\item Selecting which streams to be replayed.
	\item To which interface the streams should be replayed. This will be useful in the use case \ref{usecase:trigger}, where requesting data might happen meanwhile the historian is recording.
	\item Replay rate that allows setting how fast the replaying should happen. 
\end{itemize}

As there is no guarantee that all batboxes are powered up when the historian starts recording, the historian must be able to autodiscover streams as they become available using the presence mechanism described in section \ref{sec:analysis:streams}.

The historian should not rely on specific hardware configuration. See section \ref{section:analysis:network} for analysis of required network.
 
\begin{enumerate}
	\item The historian must support recording multiple streams to local mounted storage.
	\item The historian must support replaying while recording.
	\item The historian must be agnostic with respect to the streams' encoding.
	\item The replayed streams must be unambiguous.
	\item The historian must replay streams with all of the streams' associated metadata.
	\item The historian must be robust to stream packets arriving out-of-order or never arriving.
	\item The historian must replay streams' packets in same order as they are recorded.
	\item The historian must ignore streams that explicitly states they should not be recorded.
	\item The historian must be able to replay streams and metadata in real-time, as they are recorded.
	\item The historian must not change the stream nor metadata during replaying.
	\item The historian must replay streams such that a processing-node cannot tell whether the stream is replayed or live.
	\item The historian must support replaying the same stream multiple times.
	\item The historian must have an interface that allows requesting:
	\begin{itemize}
		\item Date and time from where the historian should replay the streams.
		\item Selecting which streams to be replayed.
		\item To which interface the streams should be replayed. 
		\item Replay rate that allows setting how fast the replaying should happen. 
		\item How many packet should be replayed.
		\item When the historian should record and for how long time.
	\end{itemize}
	The historian must not rely on specific hardware with specific properties.
	The historian must be able to discover streams as the streams appear on the network.
\end{enumerate}

Given the limited time, the requirements has been prioritized into \textit{Need to have} and \textit{Nice to have} in table \ref{sec:analysis:historian:tablefeatures}.
\begin{table}[h!]
\centering
\caption{Table prioritizing the requriements into nice-to-have and must-have}
\label{sec:analysis:historian:tablefeatures}
\begin{tabular}{l|l|l}

\multicolumn{3}{l}{Need to have}              \\ \hline
----------  & --------- & ---------------------------------- \\ \hline
----------- & --------  & --------------------------------- \\ \hline
\multicolumn{3}{l}{Nice to have}              \\ \hline
            &           &                       \\ \hline
            &           &                       \\ \hline
\end{tabular}
\end{table}

\section{Energy Calculator}
\textbf{Just some notes}
% Node responsible for calculating energy in signal. 
From use case \ref{sec:usecase:energizer}, the energy calculation should happen from bulk of samples corresponding to 1 ms. To ease the implementation of the energizer-node and future nodes, it should be possible to set the payload size of the publisher node. If the payload length of the stream corresponds to 1 ms of samples, the energizer node do not have to implement a buffer mechanism. If the length of the packet exceeds the practical limits of the network, the producer must give a warning. From the incoming data to the producer, and the outgoing data from the consumer, there should be no limit of the packet sizes.

\section{Network}
As all streams leaving the nodes are timestamped, there is no restrictions on how the devices should be connected on the network. Packets can go through different number of hobs without causing problems, if the timestamps from the streams are used, and not the order the packets are leaving the historian during replay.

To connect multiple hosts on the network, multiple switches can be connected together. If multiple switches are connected, the bandwidth between switched should be handled with care. Each batbox generates 40 Mbit/s of data, so if a 24 ports switch is used to connect 23 batboxes and one historian, the link between the switch and the historian must be 1 Gbit. If an 48 ports switch is used, 1.8 Gbits is required between the switch and the historian. It should be noted, that a switch's non-blocking capacity, meaning the bandwidth it can handle at the same time, rarely equals the (number of ports) x (the bandwidth of each port).

Each switch must support the following features in order to handle IPv6 multicast traffic properly.

\begin{itemize}
	 \item IGMP snooping, in order to avoid broadcasting multicast traffic.
	 \item MLD, protocol used by IPv6 to join and leave multicast groups.
\end{itemize}

If the system scales out enough, limitations might arise, however these are not seen as realistic limitations.

\todo{must support running on virtual interfaces}

\subsection{Requirements}
From the analysis, the following requirements can be extracted.
\subsubsection{Streams}
\begin{enumerate}
	\item The stream can be either continuous or discrete.
	\item The stream must comprise different datatypes only by relying on available codecs.
	\item The stream must be packet-oriented and stateless
	\item The stream must be transported over UDP
	\item The stream must be robust to UDP packets that arrive out of order or never arrive.
	\item The stream must be represented unambiguously
	\item Metadata must be provided by the publishers and be available to the subscribers 
\end{enumerate}
\todo{Table of requirements[Where it's defined][Where it's tested][Whether it passes}

\subsubsection{Producer \& Consumer}
\begin{enumerate}
	\item The producer and consumer must be agnostic to the stream's payload.
	\item Multiple producers must send to the same multicast group.
	\item Multiple consumers must receive from the same multicast group.
	\item The producers and consumers must implement a presence mechanism to know about other producers and consumers.
	\begin{enumerate}
		\item It must takes a finite maximum number of seconds for a producer or subscriber to know who is present. The max time must be a parameter of each node.
		\item It must take a finite maximum number of seconds for a producer or consumer to detect whether a multicast group is in use, and if yes, by whom.
		\item It must assume nodes leaving a multicast group sends a "bye".
		\item It must be robust to "bye"-messages not arriving to all nodes.
		\item It must handle nodes joining and leaving at any arbitrary time.
	\end{enumerate}
	\item The producers must be able to find unused multicast groups single-handedly.
	\item Given a unique name of a stream, the consumer must be able to resolve the multicast address of the stream.
	\item Both producers and consumers must be able to cope with nodes joining asynchronously.
	\item The producer and consumer must be implemented in C and support language bindings.
	\item The payload length of the stream should be adjustable as a parameter on the producer nodes.
		\begin{enumerate}
			\item If the requested payload size is exceeded practical limits, a warning must be given.
		\end{enumerate}
	\item There should not be a limit of the packet size of the incoming data to the producer, or outgoing data from the consumer.
	\item The producer must support streaming provided metadata to the consumers.
	\item Both producer and consumer must be agnostic with respect to the semantics of the metadata.
\end{enumerate}

\subsubsection{Metdata}

\begin{enumerate}
	\item Metadata must unambiguously relate to the continuous data stream.
	\item Metadata must be expressive.
	\item Metadata must be convertable.
	\item Metadata must be extensible.
	\item Metadata must be complete.
	\item Metadata must be hierarchical key-value pairs.
	\item The publisher and subscriber must be capable of converting between metadata formats.
	\item Events must have a start time and date
	\item Events must have a duration.
	\item Events must contain data relating to the event.
	\item Essential metadata must be retransmitted periodically
	\item None-essential metadata must be retransmitted periodically
\end{enumerate}

\subsubsection{Historian}
